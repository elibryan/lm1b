

# Make sure that first few predictions match expectations
# (where "expectations" = first few predicted results from original implementation)

import pytest
import numpy as np
import tensorflow as tf
import lm1b.utils.vocab as vocab_util
import lm1b.model.vocab_nodes as vocab_nodes
import lm1b.model.model_nodes as model_nodes
import lm1b.utils.util as util
from lm1b.utils.util import merge
import lm1b.hparams

run_config= util.load_config("config.json")

hparams= lm1b.hparams.get_default_hparams()

hparams._set_from_map({'sequence_length': 1,
                       'max_word_length': 50,
                       'chars_padding_id': 4})


graph= tf.Graph()
with graph.as_default():
    graph_nodes={}
    # Attach word / character lookup tables
    graph_nodes=merge( graph_nodes, vocab_nodes.attach_vocab_nodes(run_config['vocab_path'], hparams=hparams) )
    char_to_id_lookup_table = graph_nodes['lookup_char_to_id']
    word_to_id_lookup_table = graph_nodes['lookup_word_to_id']

    # placeholder for input sentences (encoded as character arrays)
    input_seqs=tf.placeholder(dtype=tf.int64, shape=(hparams.sequence_length, hparams.max_word_length))
    # attach the model itself
    graph_nodes=merge( graph_nodes, model_nodes.attach_inference_nodes(input_seqs, hparams=hparams))
    # attach a helper to lookup top k predictions
    graph_nodes=merge( graph_nodes,
                       model_nodes.attach_predicted_word_nodes(graph_nodes['logits'],
                                                               graph_nodes['lookup_id_to_word'],
                                                               k=10,
                                                               hparams=hparams))

    sess= tf.Session(graph=graph)
    sess.run( tf.global_variables_initializer() )
    sess.run( tf.tables_initializer() )

    # Restore the original pre-trained model into this graph
    model_nodes.restore_original_lm1b(sess, run_config=run_config)


def test_predictions():
    """For each token / timestep in test_sentence, test that the top 10 most likely words generated by this graph match
    the top 10 most likely words from the original implementation.

    Note: Original implementation is hard-coded for one token per run. Since each run touches the LSTM's state / cache,
    the same sequence can get slightly different results for different sequence_lengths. So sequence_lenght is set to 1
    for this test to make sure the results match.
    """
    with graph.as_default():
        test_sentence= "<S> I love the way pineapples drive cars"

        # Expected predictions based on the original implementation
        expected_predictions= [
            ['The', '"', 'But', 'In', 'It', 'He', 'And', 'A', 'This', 'I'],
            ["'m", 'am', 'think', 'don', "'ve", 'have', 'was', 'can', "'d", 'would'],
            ['the', 'this', 'to', 'my', 'you', 'it', 'that', 'your', 'how', 'being'],
            ['way', 'fact', 'idea', '<UNK>', '"', 'smell', 'show', 'sound', 'new', 'people'],
            ['the', 'you', 'he', 'they', 'it', 'that', 'she', 'I', 'this', 'people'],
            ['are', 'and', ',', 'have', 'can', 'grow', 'come', 'make', 'taste', 'in'],
            ['the', 'down', 'up', ',', 'a', 'out', 'and', 'their', 'in', 'to'],
            ['.', ',', 'and', 'in', '--', ':', 'through', ';', 'but', 'to'],
        ]

        actual_predictions= []

        for cur_word in test_sentence.split():
            # Encode sentence into char vectors.. Probably a better way to do this..
            cur_encoded_word=sess.run(vocab_util.encode_sequence(tf.constant([cur_word]),
                                                                 char_to_id_lookup_table=char_to_id_lookup_table,
                                                                 hparams=hparams))

            # Get predictions for the next word
            actual_predictions.extend(sess.run( graph_nodes['predicted_words'],
                                                feed_dict={input_seqs: cur_encoded_word[0]}).tolist())

        assert( np.array_equal(expected_predictions, actual_predictions) )